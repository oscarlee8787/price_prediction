{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Download Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to Binance api to download training data, no need for keys or authentication, \n",
    "# but only accessible from physical machines(does not work on Google Cloud)\n",
    "\n",
    "root_url = 'https://api.binance.com/api/v3/'\n",
    "\n",
    "check_url = root_url + 'ping'\n",
    "\n",
    "if requests.get(check_url).ok != True:\n",
    "    print('!= 200')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set api parameters including trading pairs, intervals, and desired timeframes\n",
    "\n",
    "symbol = 'BTCUSDT' # 'BTCUSDT', 'ETHUSDT', etc.\n",
    "\n",
    "interval = '1m' #'1d' , '1h', '1d'\n",
    "\n",
    "kline_url = root_url + 'klines'\n",
    "\n",
    "params = {'interval':interval,\n",
    "          'symbol':symbol,\n",
    "          'endTime':1698796800000,\n",
    "          #'limit':5 # Binance default: 500, max: 1000\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get api data as json\n",
    "\n",
    "if requests.get(url=kline_url, params=params).ok != True:\n",
    "    print('Issue with Binance kline API connectivity, did not fetch data')\n",
    "\n",
    "api_data = requests.get(url=kline_url, params=params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save json to dataframe\n",
    "\n",
    "df = pd.DataFrame(api_data)\n",
    "df.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "          'k_close_time', 'quote_asset_volume', 'num_trades',\n",
    "          'taker_base_vol', 'taker_quote_vol', 'ignore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use for loop to overcome Binance api max limit of 1000 rows per call\n",
    "\n",
    "for i in range(150):\n",
    "    prev = df['Date'][0]\n",
    "    # url_next = url + '&endTime=' + str(prev)\n",
    "    params['endTime'] = str(prev)\n",
    "    next_data = requests.get(url=kline_url, params=params).json()\n",
    "    df_next = pd.DataFrame(next_data)\n",
    "    df_next.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "          'k_close_time', 'quote_asset_volume', 'num_trades',\n",
    "          'taker_base_vol', 'taker_quote_vol', 'ignore']\n",
    "    df = pd.concat([df_next, df]).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Open', 'High', 'Low', 'Close', 'Volume',\n",
    "            'quote_asset_volume', 'num_trades',\n",
    "            'taker_base_vol', 'taker_quote_vol', 'ignore']:\n",
    "    df[col] = df[col].astype(float)\n",
    "    \n",
    "df['Date'] = pd.to_datetime(df['Date'],unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to csv\n",
    "\n",
    "filename = f'{symbol}_{interval}.csv'\n",
    "df.to_csv(f'../raw_data/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data & Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bk2m_4TChMIS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 16:01:40.369662: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,  r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqsutzJBwjS_",
    "outputId": "e7c3f28d-b281-4e29-da14-493ed67e5da3"
   },
   "outputs": [],
   "source": [
    "# Read data from the CSV file into a DataFrame\n",
    "data = pd.read_csv(\"../raw_data/BTCUSDT_1d.csv\")\n",
    "\n",
    "# Select specific columns from the DataFrame\n",
    "data = data.loc[:,['Date','Open','High','Low','Close','Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCWV-p6b-xmS",
    "outputId": "47fbcadf-5964-47cc-f26d-a9fb5ccd140f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-06</th>\n",
       "      <td>38289.32</td>\n",
       "      <td>40955.51</td>\n",
       "      <td>38215.94</td>\n",
       "      <td>39186.94</td>\n",
       "      <td>98757.311183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-07</th>\n",
       "      <td>39181.01</td>\n",
       "      <td>39700.00</td>\n",
       "      <td>37351.00</td>\n",
       "      <td>38795.69</td>\n",
       "      <td>84363.679763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-08</th>\n",
       "      <td>38795.69</td>\n",
       "      <td>46794.45</td>\n",
       "      <td>37988.89</td>\n",
       "      <td>46374.87</td>\n",
       "      <td>138597.536914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-09</th>\n",
       "      <td>46374.86</td>\n",
       "      <td>48142.19</td>\n",
       "      <td>44961.09</td>\n",
       "      <td>46420.42</td>\n",
       "      <td>115499.861712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-10</th>\n",
       "      <td>46420.42</td>\n",
       "      <td>47310.00</td>\n",
       "      <td>43727.00</td>\n",
       "      <td>44807.58</td>\n",
       "      <td>97154.182200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-28</th>\n",
       "      <td>33892.01</td>\n",
       "      <td>34493.33</td>\n",
       "      <td>33860.00</td>\n",
       "      <td>34081.00</td>\n",
       "      <td>16880.131440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-29</th>\n",
       "      <td>34081.01</td>\n",
       "      <td>34750.11</td>\n",
       "      <td>33930.00</td>\n",
       "      <td>34525.89</td>\n",
       "      <td>20685.521760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-30</th>\n",
       "      <td>34525.88</td>\n",
       "      <td>34856.00</td>\n",
       "      <td>34062.84</td>\n",
       "      <td>34474.73</td>\n",
       "      <td>33657.959760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>34474.74</td>\n",
       "      <td>34720.49</td>\n",
       "      <td>34025.00</td>\n",
       "      <td>34639.77</td>\n",
       "      <td>32737.898220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>34639.78</td>\n",
       "      <td>35582.00</td>\n",
       "      <td>34097.39</td>\n",
       "      <td>35421.43</td>\n",
       "      <td>53473.281650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close         Volume\n",
       "Date                                                             \n",
       "2021-02-06  38289.32  40955.51  38215.94  39186.94   98757.311183\n",
       "2021-02-07  39181.01  39700.00  37351.00  38795.69   84363.679763\n",
       "2021-02-08  38795.69  46794.45  37988.89  46374.87  138597.536914\n",
       "2021-02-09  46374.86  48142.19  44961.09  46420.42  115499.861712\n",
       "2021-02-10  46420.42  47310.00  43727.00  44807.58   97154.182200\n",
       "...              ...       ...       ...       ...            ...\n",
       "2023-10-28  33892.01  34493.33  33860.00  34081.00   16880.131440\n",
       "2023-10-29  34081.01  34750.11  33930.00  34525.89   20685.521760\n",
       "2023-10-30  34525.88  34856.00  34062.84  34474.73   33657.959760\n",
       "2023-10-31  34474.74  34720.49  34025.00  34639.77   32737.898220\n",
       "2023-11-01  34639.78  35582.00  34097.39  35421.43   53473.281650\n",
       "\n",
       "[999 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the 'Date' column as the index of the DataFrame\n",
    "data = data.set_index('Date')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fExReGBJz_qo"
   },
   "outputs": [],
   "source": [
    "#Set the Target column\n",
    "aim = 'Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TBA-1zdMztBG"
   },
   "outputs": [],
   "source": [
    "# 90-10 test split\n",
    "test_split_index = int(len(data) * 0.9)\n",
    "test_data = data.iloc[test_split_index:]\n",
    "available_data = data.iloc[:test_split_index]\n",
    "\n",
    "# 80-20 train-val split\n",
    "split_index = int(len(available_data) * 0.8)\n",
    "train_data = available_data.iloc[:split_index]\n",
    "val_data = available_data.iloc[split_index:]\n",
    "\n",
    "\n",
    "def line_plot(line1, line2, line3, label1=None, label2=None, label3=None, title='', lw=2):\n",
    "    \"\"\"\n",
    "    Create a line plot with two lines.\n",
    "    Parameters:\n",
    "    - line1 (array-like): Data for the first line.\n",
    "    - line2 (array-like): Data for the second line.\n",
    "    - label1 (str, optional): Label for the first line (default is None).\n",
    "    - label2 (str, optional): Label for the second line (default is None).\n",
    "    - title (str, optional): Title of the plot (default is an empty string).\n",
    "    - lw (int, optional): Line width for both lines (default is 2).\n",
    "    \"\"\"\n",
    "    # Create a subplot with specified size\n",
    "    fig, ax = plt.subplots(1, figsize=(13, 7))\n",
    "\n",
    "    # Plot the first line with its label\n",
    "    ax.plot(line1, label=label1, linewidth=lw)\n",
    "\n",
    "    # Plot the second line with its label\n",
    "    ax.plot(line2, label=label2, linewidth=lw)\n",
    "    \n",
    "    # Plot the 3rd line with its label\n",
    "    ax.plot(line3, label=label3, linewidth=lw)\n",
    "\n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel('BTC/USDT', fontsize=14)\n",
    "\n",
    "    # Set the title\n",
    "    ax.set_title(title, fontsize=16)\n",
    "\n",
    "    # Add a legend at the best location with the specified font size\n",
    "    ax.legend(loc='best', fontsize=16)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting the training and testing data for the 'Close' column\n",
    "Dont plot if using a very large dataset\n",
    "\n",
    "line_plot(train_data[aim], val_data[aim], test_data[aim], label1='Train', label2='Val', label3='Test', title='Data Split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lQi8Ho8g0V7E"
   },
   "outputs": [],
   "source": [
    "# Function to normalize a continuous variable to a zero-base scale\n",
    "def normalise_zero_base(continuous):\n",
    "    \"\"\"\n",
    "    Normalize a continuous variable to a zero-base scale.\n",
    "    Parameters:\n",
    "    - continuous (pandas.Series): The continuous variable to be normalized.\n",
    "    Returns:\n",
    "    - pandas.Series: The normalized continuous variable.\n",
    "    \"\"\"\n",
    "    # Normalize by dividing each value by the first value and subtracting 1\n",
    "    return continuous / continuous.iloc[0] - 1\n",
    "\n",
    "\n",
    "# Function to normalize a continuous variable to a min-max scale\n",
    "def normalise_min_max(continuous):\n",
    "    \"\"\"\n",
    "    Normalize a continuous variable to a min-max scale.\n",
    "    Parameters:\n",
    "    - continuous (pandas.Series): The continuous variable to be normalized.\n",
    "    Returns:\n",
    "    - pandas.Series: The normalized continuous variable.\n",
    "    \"\"\"\n",
    "    # Normalize using min-max scaling formula\n",
    "    return (continuous - continuous.min()) / (continuous.max() - continuous.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4knpG9Nn0vV1"
   },
   "outputs": [],
   "source": [
    "# Function to extract windowed data from a continuous variable\n",
    "def extract_window_data(continuous, window_len=5, zero_base=True):\n",
    "    \"\"\"\n",
    "    Extract windowed data from a continuous variable.\n",
    "    Parameters:\n",
    "    - continuous (pandas.Series): The continuous variable to extract windows from.\n",
    "    - window_len (int, optional): The length of each window (default is 5).\n",
    "    - zero_base (bool, optional): Whether to normalize each window to a zero-base scale (default is True).\n",
    "    Returns:\n",
    "    - numpy.ndarray: Array of windowed data.\n",
    "    Example:\n",
    "    >>> windowed_data = extract_window_data(data['Close'], window_len=10, zero_base=True)\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store windowed data\n",
    "    window_data = []\n",
    "\n",
    "    # Iterate over the continuous variable to extract windows\n",
    "    for idx in range(len(continuous) - window_len):\n",
    "        # Extract a window of data\n",
    "        tmp = continuous[idx: (idx + window_len)].copy()\n",
    "\n",
    "        # Normalize the window to a zero-base scale if specified\n",
    "        if zero_base:\n",
    "            tmp = normalise_zero_base(tmp)\n",
    "\n",
    "        # Append the window data to the list\n",
    "        window_data.append(tmp.values)\n",
    "\n",
    "    # Convert the list of windowed data to a numpy array\n",
    "    return np.array(window_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data for time series analysis\n",
    "def prepare_data(continuous, aim, window_len=10, zero_base=True, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Prepare data for time series analysis.\n",
    "    Parameters:\n",
    "    - continuous (pandas.Series): The continuous variable for time series analysis.\n",
    "    - aim (str): The target variable to predict.\n",
    "    - window_len (int, optional): The length of each window (default is 10).\n",
    "    - zero_base (bool, optional): Whether to normalize each window to a zero-base scale (default is True).\n",
    "    - test_size (float, optional): The proportion of data to be used as the test set (default is 0.2).\n",
    "    Returns:\n",
    "    - tuple: A tuple containing train_data, test_data, X_train, X_test, y_train, y_test.\n",
    "    \"\"\"\n",
    "    # Extract windowed data for training and testing sets\n",
    "    X_train = extract_window_data(train_data, window_len, zero_base)\n",
    "    X_val = extract_window_data(val_data, window_len, zero_base)\n",
    "\n",
    "    # Extract target variable for training and validation sets\n",
    "    y_train = train_data[aim][window_len:].values\n",
    "    y_val = val_data[aim][window_len:].values\n",
    "\n",
    "    # Normalize the target variable to a zero-base scale if specified\n",
    "    if zero_base:\n",
    "        y_train = y_train / train_data[aim][:-window_len].values - 1\n",
    "        y_val = y_val / val_data[aim][:-window_len].values - 1\n",
    "\n",
    "    # Return the prepared data\n",
    "    return train_data, val_data, X_train, X_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to prepare data for time series analysis\n",
    "def prepare_test_data(continuous, aim, window_len=10):#, zero_base=True):\n",
    "    \"\"\"\n",
    "    Prepare data for time series analysis.\n",
    "    Parameters:\n",
    "    - continuous (pandas.Series): The continuous variable for time series analysis.\n",
    "    - aim (str): The target variable to predict.\n",
    "    - window_len (int, optional): The length of each window (default is 10).\n",
    "    - zero_base (bool, optional): Whether to normalize each window to a zero-base scale (default is True).\n",
    "    - test_size (float, optional): The proportion of data to be used as the test set (default is 0.2).\n",
    "    Returns:\n",
    "    - tuple: A tuple containing train_data, test_data, X_train, X_test, y_train, y_test.\n",
    "    \"\"\"\n",
    "    # Extract windowed data for validation set\n",
    "    X_test = extract_window_data(test_data, window_len, zero_base)\n",
    "\n",
    "    # Extract target variable for validation set\n",
    "    y_test = test_data[aim][window_len:].values\n",
    "\n",
    "    # Normalize the target variable to a zero-base scale if specified\n",
    "    # if zero_base:\n",
    "    #     y_train = y_train / train_data[aim][:-window_len].values - 1\n",
    "    #     y_test = y_test / test_data[aim][:-window_len].values - 1\n",
    "\n",
    "    # Return the prepared data\n",
    "    return test_data, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close         Volume\n",
      "Date                                                             \n",
      "2021-02-06  38289.32  40955.51  38215.94  39186.94   98757.311183\n",
      "2021-02-07  39181.01  39700.00  37351.00  38795.69   84363.679763\n",
      "2021-02-08  38795.69  46794.45  37988.89  46374.87  138597.536914\n",
      "                Open      High       Low     Close        Volume\n",
      "Date                                                            \n",
      "2023-01-26  23060.42  23282.47  22850.01  23009.65  288924.43581\n",
      "2023-01-27  23009.65  23500.00  22534.88  23074.16  280833.86315\n",
      "2023-01-28  23074.16  23189.00  22878.46  23022.60  148115.71085\n",
      "                Open      High       Low     Close       Volume\n",
      "Date                                                           \n",
      "2023-07-25  29176.50  29376.00  29047.65  29228.91  21565.74780\n",
      "2023-07-26  29228.91  29690.00  29096.94  29351.96  33931.63366\n",
      "2023-07-27  29351.95  29567.49  29083.85  29222.78  22476.47626\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head(3))\n",
    "print(val_data.head(3))\n",
    "print(test_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(df: pd.DataFrame, fold_length: int, fold_stride: int) -> list[pd.DataFrame]:\n",
    "    '''\n",
    "    This function slides through the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
    "    - of equal `fold_length`\n",
    "    - using `fold_stride` between each fold\n",
    "    \n",
    "    Returns a list of folds, each as a DataFrame\n",
    "    '''\n",
    "    folds = []\n",
    "    for idx in range(0, len(df)-fold_length, fold_stride): # --> also possible to get rid of the break \n",
    "    #for idx in range(0, len(df), fold_stride):   # range(start, stop, step): for each idx in our rows at every 91 days\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        # if (idx + fold_length) > len(df):\n",
    "        #     break\n",
    "        fold = df.iloc[idx:idx + fold_length, :]  # select from row idx til last row of the fold, all the columns\n",
    "        # set last position in iloc[] to fit the column that we want\n",
    "        folds.append(fold)   # append the fold to folds\n",
    "    # return np.array(folds)\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = get_X(df=train_data, fold_length=5, fold_stride=1)\n",
    "test_x = folds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                Open      High       Low     Close         Volume\n",
       " Date                                                             \n",
       " 2021-02-06  38289.32  40955.51  38215.94  39186.94   98757.311183\n",
       " 2021-02-07  39181.01  39700.00  37351.00  38795.69   84363.679763\n",
       " 2021-02-08  38795.69  46794.45  37988.89  46374.87  138597.536914\n",
       " 2021-02-09  46374.86  48142.19  44961.09  46420.42  115499.861712\n",
       " 2021-02-10  46420.42  47310.00  43727.00  44807.58   97154.182200,\n",
       "                 Open      High       Low     Close         Volume\n",
       " Date                                                             \n",
       " 2021-02-07  39181.01  39700.00  37351.00  38795.69   84363.679763\n",
       " 2021-02-08  38795.69  46794.45  37988.89  46374.87  138597.536914\n",
       " 2021-02-09  46374.86  48142.19  44961.09  46420.42  115499.861712\n",
       " 2021-02-10  46420.42  47310.00  43727.00  44807.58   97154.182200\n",
       " 2021-02-11  44807.58  48678.90  43994.02  47969.51   89561.081454,\n",
       "                 Open      High       Low     Close         Volume\n",
       " Date                                                             \n",
       " 2021-02-08  38795.69  46794.45  37988.89  46374.87  138597.536914\n",
       " 2021-02-09  46374.86  48142.19  44961.09  46420.42  115499.861712\n",
       " 2021-02-10  46420.42  47310.00  43727.00  44807.58   97154.182200\n",
       " 2021-02-11  44807.58  48678.90  43994.02  47969.51   89561.081454\n",
       " 2021-02-12  47968.66  48985.80  46125.00  47287.60   85870.035697]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3522.94     ,  -3624.92     ,  -2232.844    ,  -3930.16     ,\n",
       "         -8117.2031714],\n",
       "       [ -2631.25     ,  -4880.43     ,  -3097.784    ,  -4321.41     ,\n",
       "        -22510.8345914],\n",
       "       [ -3016.57     ,   2214.02     ,  -2459.894    ,   3257.77     ,\n",
       "         31723.0225596],\n",
       "       [  4562.6      ,   3561.76     ,   4512.306    ,   3303.32     ,\n",
       "          8625.3473576],\n",
       "       [  4608.16     ,   2729.57     ,   3278.216    ,   1690.48     ,\n",
       "         -9720.3321544]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0].values - test_x[0].values.mean(0, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38289.32    ,  40955.51    ,  38215.94    ,  39186.94    ,\n",
       "         98757.311183],\n",
       "       [ 39181.01    ,  39700.      ,  37351.      ,  38795.69    ,\n",
       "         84363.679763],\n",
       "       [ 38795.69    ,  46794.45    ,  37988.89    ,  46374.87    ,\n",
       "        138597.536914],\n",
       "       [ 46374.86    ,  48142.19    ,  44961.09    ,  46420.42    ,\n",
       "        115499.861712],\n",
       "       [ 46420.42    ,  47310.      ,  43727.      ,  44807.58    ,\n",
       "         97154.1822  ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38289.32    , 40955.51    , 38215.94    , 39186.94    ,\n",
       "       98757.311183])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0].values[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.02275822, -0.03162494, -0.02315708, -0.01008488, -0.17061408],\n",
       "       [ 0.01305222,  0.12477847, -0.00597675,  0.15499623,  0.28745262],\n",
       "       [ 0.17435179,  0.14928029,  0.15002194,  0.15582539,  0.14495732],\n",
       "       [ 0.17516214,  0.134316  ,  0.12603334,  0.12543949, -0.01650087]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_x[0].values - test_x[0].values[0,:]) / test_x[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.00993203,  0.15160879,  0.01679149,  0.16343291,  0.39130462],\n",
       "       [ 0.15512392,  0.17535949,  0.16925946,  0.16425379,  0.26957766],\n",
       "       [ 0.15595313,  0.16085394,  0.1458138 ,  0.13417127,  0.13165159],\n",
       "       [ 0.12557183,  0.18445158,  0.15099825,  0.19124273,  0.05803192]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_x[1].values - test_x[1].values[0,:]) / test_x[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.02275822, -0.03162494, -0.02315708, -0.01008488, -0.17061408],\n",
       "        [ 0.01305222,  0.12477847, -0.00597675,  0.15499623,  0.28745262],\n",
       "        [ 0.17435179,  0.14928029,  0.15002194,  0.15582539,  0.14495732],\n",
       "        [ 0.17516214,  0.134316  ,  0.12603334,  0.12543949, -0.01650087]]),\n",
       " array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.00993203,  0.15160879,  0.01679149,  0.16343291,  0.39130462],\n",
       "        [ 0.15512392,  0.17535949,  0.16925946,  0.16425379,  0.26957766],\n",
       "        [ 0.15595313,  0.16085394,  0.1458138 ,  0.13417127,  0.13165159],\n",
       "        [ 0.12557183,  0.18445158,  0.15099825,  0.19124273,  0.05803192]]),\n",
       " array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.16343273,  0.02799499,  0.15507186,  0.00098125, -0.19998011],\n",
       "        [ 0.16425379,  0.01089727,  0.13122579, -0.03497823, -0.42657304],\n",
       "        [ 0.13417127,  0.03871184,  0.13649878,  0.03324278, -0.54751969],\n",
       "        [ 0.1912284 ,  0.04473439,  0.17639263,  0.01930168, -0.61403842]])]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero index, every first day in the 5-day window is zero, the rest are percentage change from the first day\n",
    "x = []\n",
    "for i in range(len(test_x)):\n",
    "    chg = (test_x[i].values - test_x[i].values[0,:]) / test_x[i].values\n",
    "    x.append(chg)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(df: pd.DataFrame, fold_length: int, fold_stride: int, x_len_stride):\n",
    "    '''\n",
    "    This function gets target y ('price_up column') from the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
    "    - of equal `fold_length`\n",
    "    - using `fold_stride` between each fold\n",
    "    - x_len_stride is length minus stride in the X (when predicting the next period)\n",
    "    - add an extra d to x_len_stride for extra d days into the future when predicting\n",
    "    \n",
    "    Returns a y as an numpy array\n",
    "    '''\n",
    "    folds = []\n",
    "    for idx in range(fold_stride, len(df)-fold_length, fold_stride): # --> also possible to get rid of the break \n",
    "    #for idx in range(0, len(df), fold_stride):   # range(start, stop, step): for each idx in our rows at every 91 days\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        # if (idx + fold_length) > len(df):\n",
    "        #     break\n",
    "        # fold = df['price_up'].iloc[idx:idx + fold_length]  # select from row idx til last row of the fold (3 years), all the columns\n",
    "        fold = df.iloc[:,-2].iloc[idx + x_len_stride:idx + fold_length + x_len_stride]\n",
    "        folds.append(fold)\n",
    "    # return np.array(folds)\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2021-02-06    39186.94\n",
       "2021-02-07    38795.69\n",
       "2021-02-08    46374.87\n",
       "2021-02-09    46420.42\n",
       "2021-02-10    44807.58\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0].loc[:,'Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date\n",
       " 2021-02-11    47969.51\n",
       " 2021-02-12    47287.60\n",
       " 2021-02-13    47153.69\n",
       " 2021-02-14    48577.79\n",
       " 2021-02-15    47911.10\n",
       " Name: Close, dtype: float64,\n",
       " Date\n",
       " 2021-02-12    47287.60\n",
       " 2021-02-13    47153.69\n",
       " 2021-02-14    48577.79\n",
       " 2021-02-15    47911.10\n",
       " 2021-02-16    49133.45\n",
       " Name: Close, dtype: float64,\n",
       " Date\n",
       " 2021-02-13    47153.69\n",
       " 2021-02-14    48577.79\n",
       " 2021-02-15    47911.10\n",
       " 2021-02-16    49133.45\n",
       " 2021-02-17    52119.71\n",
       " Name: Close, dtype: float64]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_y = get_y(df=train_data, fold_length=5, fold_stride=1, x_len_stride=4)\n",
    "test_y = folds_y[:3]\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44807.58"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0].loc[:,'Close'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2021-02-11    0.070567\n",
       "2021-02-12    0.055348\n",
       "2021-02-13    0.052360\n",
       "2021-02-14    0.084142\n",
       "2021-02-15    0.069263\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is the 5-day percentage change in closing price 1 day after the x window\n",
    "# !!!!!! y is the relative change to the last x date, not first!!!!!!\n",
    "# y1\n",
    "(test_y[0] - test_x[0].loc[:,'Close'][-1]) / test_x[0].loc[:,'Close'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2021-02-12   -0.014215\n",
       "2021-02-13   -0.017007\n",
       "2021-02-14    0.012681\n",
       "2021-02-15   -0.001218\n",
       "2021-02-16    0.024264\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y2\n",
    "(test_y[1] - test_x[1].loc[:,'Close'][-1]) / test_x[1].loc[:,'Close'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i, j in zip(test_x, test_y):\n",
    "    chg = (j - i.loc[:,'Close'][-1]) / i.loc[:,'Close'][-1]\n",
    "    y.append(chg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date\n",
       " 2021-02-11    0.070567\n",
       " 2021-02-12    0.055348\n",
       " 2021-02-13    0.052360\n",
       " 2021-02-14    0.084142\n",
       " 2021-02-15    0.069263\n",
       " Name: Close, dtype: float64,\n",
       " Date\n",
       " 2021-02-12   -0.014215\n",
       " 2021-02-13   -0.017007\n",
       " 2021-02-14    0.012681\n",
       " 2021-02-15   -0.001218\n",
       " 2021-02-16    0.024264\n",
       " Name: Close, dtype: float64,\n",
       " Date\n",
       " 2021-02-13   -0.002832\n",
       " 2021-02-14    0.027284\n",
       " 2021-02-15    0.013185\n",
       " 2021-02-16    0.039035\n",
       " 2021-02-17    0.102186\n",
       " Name: Close, dtype: float64]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07056685,  0.05534822,  0.05235967,  0.08414224,  0.06926328],\n",
       "       [-0.01421549, -0.01700705,  0.01268055, -0.00121765,  0.02426416],\n",
       "       [-0.00283182,  0.0272839 ,  0.01318527,  0.03903455,  0.10218556]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build an LSTM (Long Short-Term Memory) model# Function to build an LSTM (Long Short-Term Memory) model\n",
    "def build_lstm_model(input_data, output_size, neurons, activ_func='linear',\n",
    "                     dropout=0.2, loss='mse', optimizer='adam', metrics='mae'):\n",
    "    \"\"\"\n",
    "    Build an LSTM (Long Short-Term Memory) model.\n",
    "    Parameters:\n",
    "    - input_data (numpy.ndarray): The input data for the model.\n",
    "    - output_size (int): The size of the output layer.\n",
    "    - neurons (int): The number of neurons in the LSTM layer.\n",
    "    - activ_func (str, optional): Activation function for the output layer (default is 'linear').\n",
    "    - dropout (float, optional): Dropout rate to prevent overfitting (default is 0.2).\n",
    "    - loss (str, optional): Loss function for model training (default is 'mse' - Mean Squared Error).\n",
    "    - optimizer (str, optional): Optimization algorithm for model training (default is 'adam').\n",
    "    Returns:\n",
    "    - tensorflow.keras.models.Sequential: The constructed LSTM model.\n",
    "    \"\"\"\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an LSTM layer with the specified number of neurons and input shape\n",
    "    model.add(LSTM(neurons, input_shape=(input_data.shape[1], input_data.shape[2])))\n",
    "\n",
    "    # Add a Dropout layer to prevent overfitting\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    # Add a Dense layer with the specified number of units\n",
    "    model.add(Dense(units=output_size))\n",
    "\n",
    "    # Add an Activation layer with the specified activation function\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    # Compile the model with the specified loss function and optimizer\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    # Return the constructed LSTM model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdEmnpEz01dg"
   },
   "outputs": [],
   "source": [
    "# Define parameters for data preparation and LSTM model\n",
    "window_len = 15\n",
    "test_size = 0.2\n",
    "zero_base = True\n",
    "lstm_neurons = 50\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "loss = 'mse'\n",
    "dropout = 0.24\n",
    "optimizer = 'adam'\n",
    "output_size = 1\n",
    "\n",
    "# Prepare data for time series analysis\n",
    "train_data, val_data, X_train, X_val, y_train, y_val = prepare_data(\n",
    "    available_data, aim, window_len=window_len, zero_base=zero_base, test_size=test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test set\n",
    "test_data, X_test, y_test = prepare_test_data(test_data, aim=aim, window_len=window_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data, X_train_val, X_test_val, y_train_val, y_test_val = prepare_data(\n",
    "#     val_data, aim, window_len=window_len, zero_base=True, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1TEOxBr1ALy",
    "outputId": "51104b89-80ab-47aa-9031-9cc12a5cd0a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build an LSTM model\n",
    "model = build_lstm_model(\n",
    "    X_train, output_size=output_size, neurons=lstm_neurons, dropout=dropout, loss=loss, optimizer=optimizer)\n",
    "\n",
    "# Train the LSTM model\n",
    "modelfit = model.fit(\n",
    "    X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, verbose=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to put preprocessing into model building pipeline, or check preprocessing for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build an LSTM (Long Short-Term Memory) model# Function to build an LSTM (Long Short-Term Memory) model\n",
    "def build_lstm_big(input_data, output_size, neurons, activ_func='linear',\n",
    "                     dropout=0.2, loss='mse', optimizer='adam', metrics='mae'):\n",
    "    \"\"\"\n",
    "    Build another LSTM with different architecture\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(neurons, input_shape=(input_data.shape[1], input_data.shape[2]), return_sequences=True))\n",
    "    \n",
    "    model.add(LSTM(neurons, return_sequences=True))\n",
    "    # model.add(Dropout(dropout))\n",
    "    \n",
    "#     model.add(LSTM(neurons, return_sequences=True))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    # Add a Dense layer with the specified number of units\n",
    "    model.add(Dense(units=output_size, activation=activ_func))\n",
    "    \n",
    "\n",
    "    # Compile the model with the specified loss function and optimizer\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    # Return the constructed LSTM model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=2)\n",
    "\n",
    "# Build big LSTM model\n",
    "model_big = build_lstm_big(\n",
    "    X_train, output_size=output_size, neurons=lstm_neurons, dropout=dropout, loss=loss, optimizer=optimizer)\n",
    "\n",
    "# Train the LSTM model\n",
    "history_big = model_big.fit(\n",
    "    X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, verbose=1, shuffle=False, callbacks=es)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_big.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modelfit.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data so that the model looks at past 15 minutes of data and predicts the price in 5 minutes, instead of in 1 minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4.1 BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "tiny_bert = TFAutoModel.from_pretrained('prajjwal1/bert-tiny', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiny_bert.compile(optimizer='adam',\n",
    "                  metrics='accuracy'\n",
    "                 )\n",
    "tiny_bert.fit(X_train, y_train, validation_data=(X_val, y_val), shuffle=False, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "    # --- LOSS --- \n",
    "\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "\n",
    "    # ax[0].set_ylim((0,3))\n",
    "\n",
    "    ax[0].legend(['Train', 'Validation'], loc='best')\n",
    "\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    # --- ACCURACY\n",
    "\n",
    "    ax[1].plot(history.history['mae'])\n",
    "    ax[1].plot(history.history['val_mae'])\n",
    "\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('MAE')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "\n",
    "    ax[1].legend(['Train', 'Validation'], loc='best')\n",
    "\n",
    "    # ax[1].set_ylim((0,1))\n",
    "\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(modelfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "m5ilATOy1ZqE",
    "outputId": "e4f214de-dec9-4030-ff53-6677e7c18f87"
   },
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss during model training\n",
    "plt.plot(modelfit.history['loss'], 'r', linewidth=2, label='Training loss')\n",
    "plt.plot(modelfit.history['val_loss'], 'g', linewidth=2, label='Validation loss')\n",
    "\n",
    "# Set plot title and axis labels\n",
    "plt.title('LSTM Neural Networks - BTC Model')\n",
    "plt.xlabel('Epochs numbers')\n",
    "plt.ylabel('MSE numbers')\n",
    "\n",
    "# Display legend to distinguish between training and validation loss\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[aim][window_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyfyB5SA1saZ",
    "outputId": "da16ff40-07cf-4357-8e5f-861ce75ac98e"
   },
   "outputs": [],
   "source": [
    "# Extract the target values from the test dataset\n",
    "targets = test_data[aim][window_len:]\n",
    "\n",
    "# Make predictions using the trained LSTM model on the validation data\n",
    "preds = model_big.predict(X_test).squeeze()\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE) between predictions and actual targets\n",
    "mae = mean_absolute_error(preds, y_test)\n",
    "\n",
    "# Display the actual target values\n",
    "targets.round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "ICd7mlF_1861",
    "outputId": "7a04803a-8db1-4ec0-8300-088eb8f1b734"
   },
   "outputs": [],
   "source": [
    "# Generate final predictions by reversing the normalization process\n",
    "preds = test_data[aim].values[:-window_len] * (preds + 1)\n",
    "\n",
    "# Create a pandas Series with index and data for predictions\n",
    "preds = pd.Series(index=targets.index, data=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the actual and predicted values\n",
    "Cannot plot if dataset is large\n",
    "line_plot(targets, preds, 'actual', 'prediction', lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn preds to numpy array for MSE and R2 calculations\n",
    "preds = preds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJbbB0Ji1u3z",
    "outputId": "ececa6bb-84a9-4f39-ce98-c31d9a4bdc5f"
   },
   "outputs": [],
   "source": [
    "# Calculate the Mean Squared Error (MSE) between predictions and actual targets\n",
    "SCORE_MSE = mean_squared_error(preds, y_test)\n",
    "SCORE_RMSE = mean_squared_error(preds, y_test, squared=False)\n",
    "\n",
    "# Display the calculated MSE score\n",
    "SCORE_MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYFWq3gI10a6",
    "outputId": "a9c0623e-b434-4962-8649-57a18d4efefb"
   },
   "outputs": [],
   "source": [
    "# Calculate the R-squared (R2) score between actual targets and predicted values\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "# Multiply the R2 score by 100 for percentage representation\n",
    "r2 * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_big.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- END OF NOTEBOOK --\n",
    "-- CELLS BELOW ARE STILL IN PRODUCTION --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. Preprocess Data for Binary Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is the DataFrame containing time series data\n",
    "data['aim_binary'] = (data['Close'] > data['Close'].shift(1)).astype(int)\n",
    "\n",
    "# Drop NaN values introduced by the shift operation\n",
    "data = data.dropna()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_data_binary(continuous, aim, window_len=10, zero_base=True, test_size=0.2):\n",
    "#     X_train = extract_window_data(train_data[continuous.columns], window_len, zero_base)\n",
    "#     X_test = extract_window_data(test_data[continuous.columns], window_len, zero_base)\n",
    "#     y_train = train_data[aim][window_len:].values\n",
    "#     y_test = test_data[aim][window_len:].values\n",
    "#     if zero_base:\n",
    "#         y_train = y_train / train_data[aim][:-window_len].values - 1\n",
    "#         y_test = y_test / test_data[aim][:-window_len].values - 1\n",
    "\n",
    "#     return train_data, test_data, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for binary classification\n",
    "aim_binary = 'aim_binary'\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=[aim_binary]), data[aim_binary], test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a binary classification model\n",
    "def build_binary_classification_model(input_data, output_size, neurons, activ_func='sigmoid', dropout=0.3, loss='binary_crossentropy', optimizer='adam'):\n",
    "    model2 = Sequential()\n",
    "    # Assuming your time series data has only one feature (e.g., 'Close' column)\n",
    "    model2.add(LSTM(neurons, input_shape=(X_train.shape[1], 1)))  # Adjust the input shape\n",
    "    model2.add(Dropout(dropout))\n",
    "    model2.add(Dense(units=output_size))\n",
    "    model2.add(Activation(activ_func))\n",
    "    model2.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters for the binary classification model\n",
    "binary_lstm_neurons = 50\n",
    "binary_epochs = 20\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the binary classification model\n",
    "binary_model = build_binary_classification_model(X_train, output_size=1, neurons=binary_lstm_neurons)\n",
    "\n",
    "# Train the binary classification model\n",
    "binary_modelfit = binary_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=binary_epochs, batch_size=batch_size, verbose=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 8. Binary Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss during model training\n",
    "plt.plot(binary_modelfit.history['loss'], 'r', linewidth=2, label='Training loss')\n",
    "plt.plot(binary_modelfit.history['val_loss'], 'g', linewidth=2, label='Validation loss')\n",
    "\n",
    "# Set plot title and axis labels\n",
    "plt.title('LSTM Neural Networks - BTC Model')\n",
    "plt.xlabel('Epochs numbers')\n",
    "plt.ylabel('MSE numbers')\n",
    "\n",
    "# Display legend to distinguish between training and validation loss\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions using the trained binary classification model on the test data\n",
    "binary_preds = (binary_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Extract the binary target values from the test dataset\n",
    "binary_targets = y_test.astype(int)\n",
    "\n",
    "# Display the actual binary target values\n",
    "print(\"Actual Binary Targets:\")\n",
    "print(binary_targets)\n",
    "\n",
    "# Display the predicted binary target values\n",
    "print(\"Predicted Binary Targets:\")\n",
    "print(binary_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the binary classification model\n",
    "binary_preds = (binary_model.predict(X_test) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, binary_preds)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled11.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
